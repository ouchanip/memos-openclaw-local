# MemOS Environment Variables
# Copy to .env and adjust values for your environment

## Base
TZ=Asia/Tokyo
MOS_CUBE_PATH=/tmp/data_test
MEMOS_BASE_PATH=.
MOS_ENABLE_DEFAULT_CUBE_CONFIG=true
MOS_ENABLE_REORGANIZE=false
MOS_TEXT_MEM_TYPE=tree_text
ASYNC_MODE=sync

## User/session defaults
MOS_TOP_K=50

## Chat LLM — Ollama via OpenAI-compatible API
MOS_CHAT_MODEL=gemma3:4b
MOS_CHAT_TEMPERATURE=0.8
MOS_MAX_TOKENS=2048
MOS_TOP_P=0.9
MOS_CHAT_MODEL_PROVIDER=openai
OPENAI_API_KEY=ollama
OPENAI_API_BASE=http://host.docker.internal:11434/v1

## MemReader / retrieval LLM — same Ollama
MEMRADER_MODEL=gemma3:4b
MEMRADER_API_KEY=ollama
MEMRADER_API_BASE=http://host.docker.internal:11434/v1
MEMRADER_MAX_TOKENS=5000

## Embedding — Ollama backend
EMBEDDING_DIMENSION=1024
MOS_EMBEDDER_BACKEND=ollama
OLLAMA_API_BASE=http://host.docker.internal:11434
MOS_EMBEDDER_MODEL=qwen3-embedding:0.6b

## Reranker — cosine local (no external service needed)
MOS_RERANKER_BACKEND=cosine_local
MOS_RERANKER_STRATEGY=single_turn

## Graph / vector stores
NEO4J_BACKEND=neo4j-community
NEO4J_URI=bolt://host.docker.internal:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password_here
NEO4J_DB_NAME=neo4j
MOS_NEO4J_SHARED_DB=false
QDRANT_HOST=qdrant-memos
QDRANT_PORT=6333

## Scheduler — off
MOS_ENABLE_SCHEDULER=false
API_SCHEDULER_ON=false

## Preference memory — off (requires Milvus)
ENABLE_PREFERENCE_MEMORY=false

## Internet search — off
ENABLE_INTERNET=false
